# ğŸŒ¦ï¸ Weather Data Pipeline

A **data engineering project** that fetches weather data from an API, transforms it into clean records, and stores it inside a SQLite database for querying and reporting.

---

## ğŸ“Œ Overview
This project demonstrates a simple **ETL pipeline**:

1. **Extract** â†’ Get raw weather data from API
2. **Transform** â†’ Clean & structure the data
3. **Load** â†’ Store into SQLite database
4. **Report** â†’ Query and analyze stored data

---

## ğŸ§° Tech Stack
- Python 3
- SQLite
- Requests
- JSON
- VS Code + SQLite Extension (optional for viewing DB)

---

## ğŸ—‚ï¸ Project Structure
```
weather_pipeline/
â”‚
â”œâ”€â”€ fetch.py        # Extract data from API
â”œâ”€â”€ transform.py    # Clean & structure the data
â”œâ”€â”€ load.py         # Store data into SQLite
â”œâ”€â”€ report.py       # Query and analyze data
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ weather.json   # Raw API response
    â””â”€â”€ weather.db     # Final database
```

---

## âš™ï¸ Setup
Create a virtual environment and install dependencies:

```bash
python3 -m venv venv
source venv/bin/activate
pip install requests
```

---

## â–¶ï¸ Run The Pipeline
Run scripts in order:

```bash
python fetch.py
python transform.py
python load.py
python report.py
```

---

## ğŸ—ƒï¸ Database Output
The pipeline creates:

```
data/weather.db
```

Contains table:

| datetime | temperature |
|--------|------|
| 2026-02-19 00:00 | 4.8 |
| 2026-02-19 01:00 | 4.8 |
| ... | ... |

---

## ğŸ” Example SQL Query
```sql
SELECT AVG(temperature) FROM weather;
```

---

## ğŸ‘¤ Author
**Beimnet Tefera**

